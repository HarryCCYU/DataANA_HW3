{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 Predict the Stock\n",
    "E94041173 張竣佑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2009      902.99       931.80      934.73     899.35  4048270080\n",
      "1  05-Jan-2009      929.17       927.45      936.63     919.53  5413910016\n",
      "2  06-Jan-2009      931.17       934.70      943.85     927.28  5392620032\n",
      "3  07-Jan-2009      927.45       906.65      927.45     902.37  4704940032\n",
      "4  08-Jan-2009      905.73       909.73      910.00     896.81  4991549952\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2018     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1  03-Jan-2018     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2  04-Jan-2018     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3  05-Jan-2018     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4  08-Jan-2018     2742.67      2747.71     2748.51    2737.60  1894823936\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "train_data = pd.read_csv('./training_data.csv')\n",
    "test_data = pd.read_csv('./testing_data.csv')\n",
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 5)\n",
      "(251, 5)\n",
      "(2263,)\n",
      "(251,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_train = train_data.drop('Date',axis=1)\n",
    "x_test = test_data.drop('Date',axis=1)\n",
    "def Get_label(data):\n",
    "    label_list = list()\n",
    "    for i in range(len(data)-1):\n",
    "        if data['Close Price'][i+1]-data['Close Price'][i] >= 0:\n",
    "            label_list.append(1)\n",
    "        else:\n",
    "            label_list.append(0)\n",
    "    return np.array(label_list)\n",
    "# y_train = Get_label(x_train['Close Price'])   \n",
    "# y_test = Get_label(x_test['Close Price'])\n",
    "y_train = Get_label(x_train)   \n",
    "y_test = Get_label(x_test)\n",
    "# x_train['TODAYwinloss'] = np.hstack((0,y_train))\n",
    "# x_test['TODAYwinloss'] = np.hstack((0,y_test))\n",
    "x_train = x_train[:-1]\n",
    "x_test = x_test[:-1]\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "# x_train = preprocessing.normalize(x_train)\n",
    "# x_test = preprocessing.normalize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0      902.99       931.80      934.73     899.35  4048270080\n",
      "1      929.17       927.45      936.63     919.53  5413910016\n",
      "2      931.17       934.70      943.85     927.28  5392620032\n",
      "3      927.45       906.65      927.45     902.37  4704940032\n",
      "4      905.73       909.73      910.00     896.81  4991549952 [0 1 0 1 0]\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4     2742.67      2747.71     2748.51    2737.60  1894823936\n",
      "5     2751.15      2751.29     2759.14    2747.86  1957263872\n",
      "6     2745.55      2748.23     2750.80    2736.06  2048867328\n",
      "7     2752.97      2767.56     2767.56    2752.78  1978592384\n",
      "8     2770.18      2786.24     2787.85    2769.64  2108422912\n",
      "9     2798.96      2776.42     2807.54    2768.64  2532135680 [1 1 1 1 1 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:5],y_train[:5])\n",
    "print(x_test[:10],y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTICREGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用五天的open_price、close_price共10個值當features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 20) (2254, 20) (242,) (2254,)\n"
     ]
    }
   ],
   "source": [
    "close_price_tr = x_train['Close Price']\n",
    "open_price_tr = x_train['Open Price']\n",
    "close_price_te = x_test['Close Price']\n",
    "open_price_te = x_test['Open Price']\n",
    "LG_x_train = list()\n",
    "LG_y_train = list()\n",
    "LG_x_test = list()\n",
    "LG_y_test = list()\n",
    "for i in range(len(close_price_tr)-9):\n",
    "    cp_tr = close_price_tr[i:i+10]\n",
    "    op_tr = open_price_tr[i:i+10]\n",
    "    combine_tr = np.hstack((cp_tr,op_tr))\n",
    "    LG_x_train.append(combine_tr)\n",
    "    LG_y_train.append(y_train[i+9])\n",
    "for i in range(len(close_price_te)-9):\n",
    "    cp_te = close_price_te[i:i+10]\n",
    "    op_te = open_price_te[i:i+10]\n",
    "    combine_te = np.hstack((cp_te,op_te))\n",
    "    LG_x_test.append(combine_te)\n",
    "    LG_y_test.append(y_test[i+9])\n",
    "        \n",
    "LG_x_train = np.array(LG_x_train)\n",
    "LG_y_train = np.array(LG_y_train)\n",
    "LG_x_test = np.array(LG_x_test)\n",
    "LG_y_test = np.array(LG_y_test)\n",
    "\n",
    "print(LG_x_test.shape,LG_x_train.shape,LG_y_test.shape,LG_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 原本只使用一天的資料當features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5258964143426295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = LogisticRegression()\n",
    "clf.fit(x_train,y_train)\n",
    "prediction = clf.predict(x_test)\n",
    "print(accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用五天資料的預測模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5041322314049587\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression()\n",
    "clf2.fit(LG_x_train,LG_y_train)\n",
    "prediction = clf2.predict(LG_x_test)\n",
    "print(accuracy_score(LG_y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整理資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 4) (2263, 4) (2263,)\n"
     ]
    }
   ],
   "source": [
    "# SVM_cp = train_data['Close Price']\n",
    "# SVM_y_train = SVM_cp[1::]\n",
    "SVM_y_train = np.array(y_train)\n",
    "SVM_y_test = np.array(y_test)\n",
    "SVM_x_train = x_train.drop('Volume',axis=1)\n",
    "SVM_x_test = x_test.drop('Volume',axis=1)\n",
    "SVM_x_train = np.array(SVM_x_train)\n",
    "SVM_x_test = np.array(SVM_x_test)\n",
    "SVM_y_train = np.array(SVM_y_train)\n",
    "print(SVM_x_test.shape,SVM_x_train.shape,SVM_y_train.shape)\n",
    "# for i in SVM_y_train:\n",
    "#     print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5258964143426295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf3 = SVC(C=0.5,kernel='rbf',probability=True)\n",
    "clf3.fit(SVM_x_train,SVM_y_train)\n",
    "# clf3.fit(LG_x_train,LG_y_train)\n",
    "prediction = clf3.predict(SVM_x_test)\n",
    "print(accuracy_score(SVM_y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 5) (2263, 5) (2263, 2) (251, 2)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "NN_x_train = np.array(x_train)\n",
    "NN_x_test = np.array(x_test)\n",
    "NN_y_train = np.array(y_train)\n",
    "NN_y_train = keras.utils.to_categorical(NN_y_train,2)\n",
    "NN_y_test = np.array(y_test)\n",
    "NN_y_test = keras.utils.to_categorical(NN_y_test,2)\n",
    "print(NN_x_test.shape,NN_x_train.shape,NN_y_train.shape,NN_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_126 (Dense)            (None, 8)                 48        \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 650\n",
      "Trainable params: 634\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Train on 2263 samples, validate on 251 samples\n",
      "Epoch 1/5\n",
      "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7733 - acc: 0.5303 - val_loss: 0.6983 - val_acc: 0.5259\n",
      "Epoch 2/5\n",
      "2263/2263 [==============================] - 0s 213us/step - loss: 0.7767 - acc: 0.5356 - val_loss: 0.7234 - val_acc: 0.5259\n",
      "Epoch 3/5\n",
      "2263/2263 [==============================] - 0s 220us/step - loss: 0.7686 - acc: 0.5334 - val_loss: 0.6972 - val_acc: 0.4741\n",
      "Epoch 4/5\n",
      "2263/2263 [==============================] - 1s 224us/step - loss: 0.7665 - acc: 0.5365 - val_loss: 0.7334 - val_acc: 0.5259\n",
      "Epoch 5/5\n",
      "2263/2263 [==============================] - 0s 211us/step - loss: 0.7650 - acc: 0.5307 - val_loss: 0.7260 - val_acc: 0.5259\n",
      "251/251 [==============================] - 0s 83us/step\n",
      "Test loss: 0.7259586612541837\n",
      "Test accuracy: 0.525896415529973\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential      ###模型選擇###\n",
    "from keras.layers import Dense,Dropout   ###用於定義神經網路層###\n",
    "from keras.optimizers import Adam     ###選擇優化器###\n",
    "from keras.layers import BatchNormalization \n",
    "from keras.layers import Conv1D,MaxPooling1D,Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "###---###\n",
    "NN_x_train = preprocessing.normalize(NN_x_train)\n",
    "NN_x_test = preprocessing.normalize(NN_x_test)\n",
    "###---------建構模型--------###\n",
    "model = Sequential()                                              ###TOBEDEFINE選擇原因###\n",
    "model.add(Dense(8,activation = 'relu',input_shape = (5,)))    ###建構第一層輸入層###\n",
    "model.add(Dropout(0.2))                                           ###防止OVERFITTING捨棄0.2%的層數###\n",
    "model.add(Dense(16,activation = 'relu'))                         ###建構隱藏層###\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(16,activation = 'relu'))                         ###建構隱藏層###\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(8,activation = 'relu'))                         ###建構隱藏層###\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2,activation = 'softmax'))                       ###輸出層###\n",
    "model.summary()\n",
    "###-------調整模型參數-------###\n",
    "model.compile(loss = 'categorical_crossentropy',                  ###LOSS FUNCTION使用一般CROSSRNTROPY###\n",
    "             optimizer = Adam(lr=0.1),                               ###優化器###\n",
    "             metrics = ['accuracy'])                              ###準確率使用accuracy###\n",
    "\n",
    "class_weight = {\n",
    "    0: 1.,\n",
    "    1: 1239 / 1025\n",
    "}\n",
    "###---------training---------###\n",
    "history = model.fit(NN_x_train,NN_y_train,batch_size = 8,epochs = 5,verbose = 1, ###fitting data###\n",
    "         validation_data = (NN_x_test,NN_y_test),class_weight=class_weight)\n",
    "'''\n",
    "batch_size = 64 --> 每次訓練丟64張圖片\n",
    "epochs = 2 --> 訓練2輪\n",
    "verbose = 1 --> 選擇輸出訊息方式,0不輸出,1一直輸出更新,2每個epoch輸出一次\n",
    "'''\n",
    "\n",
    "###---------計算score---------###\n",
    "\n",
    "score = model.evaluate(NN_x_test,NN_y_test,verbose = 1)\n",
    "print('Test loss:',score[0])\n",
    "print('Test accuracy:',score[1])\n",
    "\n",
    "###------done the mission------###\n",
    "losses = history.history['loss']\n",
    "plt.plot(range(len(losses)), losses, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
